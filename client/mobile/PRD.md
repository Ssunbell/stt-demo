# 📋 PRD: Real-time Voice Streaming to STT Mobile App

## 문서 정보

| 항목 | 내용 |
|------|------|
| **문서 버전** | 1.0 |
| **작성일** | 2025-12-13 |
| **제품명** | Real-time STT Mobile App |
| **플랫폼** | React Native (iOS, Android) |
| **상태** | Draft |

---

## 1. 제품 개요 (Executive Summary)

### 1.1. 제품 비전

사용자가 음성으로 입력한 내용을 실시간으로 텍스트로 변환하여, 저지연(Low Latency) 환경에서 즉각적인 피드백을 제공하는 모바일 애플리케이션입니다. 음성 인식 기술을 통해 메모 작성, 문서 작성, 번역 등 다양한 생산성 시나리오를 지원합니다.

### 1.2. 핵심 가치 제안 (Value Proposition)

- **즉각적인 피드백**: 사용자가 말하는 동시에 텍스트로 변환되는 실시간 경험
- **높은 정확도**: 최신 STT 엔진(Google, AWS, Whisper 등) 활용
- **부분 결과 제공**: 문장 완성 전 중간 인식 결과(Interim Results) 표시로 UX 향상
- **크로스 플랫폼**: React Native 기반으로 iOS와 Android 동시 지원

### 1.3. 비즈니스 목표

- 음성 기반 생산성 도구 시장 진입
- 실시간 STT 기술력 확보 및 검증
- 향후 다국어 지원 및 엔터프라이즈 솔루션으로 확장 가능한 기반 마련

---

## 2. 타겟 사용자 (Target Users)

### 2.1. 주요 페르소나

#### 페르소나 1: 디지털 노마드 김준호 (32세)
- **직업**: 프리랜서 작가
- **니즈**: 이동 중에도 아이디어를 빠르게 메모하고 싶음
- **페인포인트**: 타이핑이 느리고 불편함, 음성 메모는 나중에 다시 들어야 하는 번거로움
- **사용 시나리오**: 카페나 대중교통에서 떠오른 아이디어를 음성으로 즉시 텍스트화

#### 페르소나 2: 비서 이지은 (28세)
- **직업**: 기업 임원 비서
- **니즈**: 회의 내용을 빠르게 기록하고 정리해야 함
- **페인포인트**: 속기가 어렵고, 놓치는 내용이 많음
- **사용 시나리오**: 회의 중 주요 내용을 실시간으로 텍스트로 변환하여 회의록 작성

#### 페르소나 3: 학생 박민수 (24세)
- **직업**: 대학생
- **니즈**: 강의 내용을 효율적으로 필기하고 싶음
- **페인포인트**: 강의 속도가 빨라 타이핑으로 따라가기 어려움
- **사용 시나리오**: 교수님의 강의를 실시간으로 텍스트로 변환하여 노트 작성

---

## 3. 기능 요구사항 (Functional Requirements)

### 3.1. 핵심 기능 (Core Features)

#### F1. 실시간 음성 녹음
- **우선순위**: P0 (필수)
- **설명**: 사용자가 마이크 버튼을 누르면 실시간으로 음성을 캡처
- **상세 요구사항**:
  - 마이크 권한 요청 및 처리 (iOS, Android)
  - 16kHz, Mono, PCM 16bit 포맷으로 오디오 샘플링
  - 100ms~200ms 단위의 청크로 버퍼링
  - 녹음 상태를 시각적으로 표시 (녹음 중/대기/정지)

#### F2. 실시간 텍스트 변환
- **우선순위**: P0 (필수)
- **설명**: 녹음된 음성을 실시간으로 텍스트로 변환
- **상세 요구사항**:
  - WebSocket을 통한 서버와의 양방향 통신
  - Binary 형태로 오디오 데이터 전송 (Base64 인코딩)
  - 중간 인식 결과(Interim Results)와 최종 결과(Final Results) 구분
  - 지연 시간(Latency) 최소화 (목표: 500ms 이하)

#### F3. 부분 결과 표시 (Interim Results)
- **우선순위**: P0 (필수)
- **설명**: 문장이 완성되기 전에도 중간 인식 결과를 표시
- **상세 요구사항**:
  - 중간 결과는 회색 또는 투명도를 적용하여 표시
  - 최종 결과는 확정된 검은색 텍스트로 표시
  - 중간 결과가 최종 결과로 업데이트될 때 부드러운 전환 효과

#### F4. 오디오 시각화 (Audio Visualizer)
- **우선순위**: P1 (중요)
- **설명**: 마이크 입력을 시각적으로 표현하여 사용자 피드백 제공
- **상세 요구사항**:
  - 실시간 음량 레벨 표시 (볼륨 미터)
  - 파형(Waveform) 또는 스펙트럼 시각화
  - 마이크 작동 여부를 명확히 인지할 수 있는 UI

#### F5. 텍스트 편집 및 저장
- **우선순위**: P1 (중요)
- **설명**: 변환된 텍스트를 편집하고 저장
- **상세 요구사항**:
  - 변환 완료 후 텍스트 수정 가능
  - 로컬 저장 또는 클라우드 동기화 옵션
  - 복사/공유 기능

#### F6. 오류 처리 및 재연결
- **우선순위**: P0 (필수)
- **설명**: 네트워크 오류 발생 시 자동 재연결 및 사용자 알림
- **상세 요구사항**:
  - WebSocket 연결 끊김 감지
  - 자동 재연결 시도 (최대 3회)
  - 연결 실패 시 사용자에게 명확한 오류 메시지 표시
  - 녹음 중 끊김 시 로컬 버퍼링 후 재연결 시 전송

### 3.2. 부가 기능 (Additional Features)

#### F7. 다국어 지원
- **우선순위**: P2 (향후 고려)
- **설명**: 한국어 외 영어, 중국어, 일본어 등 다국어 음성 인식

#### F8. 커스텀 단어장
- **우선순위**: P2 (향후 고려)
- **설명**: 전문 용어나 고유명사를 사전 등록하여 인식률 향상

#### F9. 음성 명령
- **우선순위**: P2 (향후 고려)
- **설명**: "줄바꿈", "마침표" 등 음성 명령으로 텍스트 편집

---

## 4. 비기능 요구사항 (Non-Functional Requirements)

### 4.1. 성능 (Performance)

| 지표 | 목표 | 측정 방법 |
|------|------|-----------|
| **음성-텍스트 변환 지연** | 500ms 이하 | 발화 종료 시점부터 최종 텍스트 표시까지 시간 측정 |
| **WebSocket 연결 시간** | 2초 이하 | 녹음 버튼 클릭부터 연결 완료까지 시간 측정 |
| **앱 시작 시간** | 3초 이하 | 앱 아이콘 클릭부터 첫 화면 표시까지 시간 측정 |
| **메모리 사용량** | 200MB 이하 | 녹음 중 최대 메모리 사용량 측정 |
| **배터리 소모** | 시간당 10% 이하 | 1시간 연속 녹음 시 배터리 소모율 측정 |

### 4.2. 확장성 (Scalability)

- 동시 접속 사용자 1,000명 이상 지원 (서버 기준)
- 1시간 이상 연속 녹음 지원 (클라이언트 기준)

### 4.3. 보안 (Security)

- WebSocket 통신은 WSS(WebSocket Secure) 사용
- 오디오 데이터는 전송 중 암호화
- 민감한 데이터는 로컬에 암호화하여 저장
- 사용자 음성 데이터는 서버에 저장하지 않음 (프라이버시 준수)

### 4.4. 호환성 (Compatibility)

| 플랫폼 | 최소 버전 | 목표 버전 |
|--------|-----------|-----------|
| **iOS** | iOS 13.0 이상 | iOS 15.0 이상 |
| **Android** | Android 8.0 (API 26) 이상 | Android 12.0 (API 31) 이상 |

### 4.5. 사용성 (Usability)

- 첫 사용자도 3분 이내에 기본 기능 사용 가능
- 마이크 권한 요청 시 명확한 설명 제공
- 오류 발생 시 사용자가 이해할 수 있는 언어로 메시지 표시

### 4.6. 접근성 (Accessibility)

- VoiceOver(iOS) 및 TalkBack(Android) 지원
- 색상 대비 WCAG 2.1 AA 기준 준수
- 큰 텍스트 모드 지원

---

## 5. 기술 스택 및 아키텍처

### 5.1. 클라이언트 (React Native)

| 구분 | 기술 | 비고 |
|------|------|------|
| **언어** | TypeScript | 타입 안정성 확보 |
| **프레임워크** | React Native | iOS, Android 크로스 플랫폼 |
| **오디오 라이브러리** | `react-native-live-audio-stream` | 실시간 Raw PCM 데이터 추출 |
| **통신** | Native WebSocket | 표준 WebSocket API 사용 |
| **상태 관리** | React Hooks (useState, useRef) | 경량 상태 관리 |
| **UI 라이브러리** | React Native Paper / NativeWind | 디자인 시스템 적용 |

### 5.2. 서버 (Backend)

| 구분 | 기술 | 비고 |
|------|------|------|
| **언어** | Python 또는 Node.js | Python 권장 (FastAPI, WebSocket 지원) |
| **프레임워크** | FastAPI (Python) / Express (Node.js) | WebSocket 지원 |
| **STT 엔진** | Google Cloud Speech-to-Text / AWS Transcribe / OpenAI Whisper | 다중 엔진 지원 고려 |
| **통신** | WebSocket | 양방향 실시간 통신 |
| **배포** | Docker + Kubernetes / AWS ECS | 컨테이너 기반 배포 |

### 5.3. 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────┐
│                    Client (React Native)                │
│  ┌──────────────────────────────────────────────────┐  │
│  │  1. Microphone Input (16kHz, Mono, PCM 16bit)    │  │
│  │  2. Audio Buffering (100-200ms chunks)           │  │
│  │  3. Base64 Encoding                              │  │
│  └────────────────────┬─────────────────────────────┘  │
└────────────────────────┼────────────────────────────────┘
                         │
                         │ WebSocket (WSS)
                         │
┌────────────────────────▼────────────────────────────────┐
│                    Server (Python/Node.js)              │
│  ┌──────────────────────────────────────────────────┐  │
│  │  1. WebSocket Connection Handler                 │  │
│  │  2. Base64 Decode → Binary (PCM)                 │  │
│  │  3. Stream Pipeline to STT Engine                │  │
│  │  4. VAD (Voice Activity Detection) - Optional    │  │
│  └────────────────────┬─────────────────────────────┘  │
└────────────────────────┼────────────────────────────────┘
                         │
                         │ gRPC / REST API
                         │
┌────────────────────────▼────────────────────────────────┐
│                    STT Engine                           │
│  ┌──────────────────────────────────────────────────┐  │
│  │  Google Cloud Speech-to-Text                     │  │
│  │  AWS Transcribe                                  │  │
│  │  OpenAI Whisper                                  │  │
│  └────────────────────┬─────────────────────────────┘  │
└────────────────────────┼────────────────────────────────┘
                         │
                         │ Text Result (Interim / Final)
                         │
┌────────────────────────▼────────────────────────────────┐
│                    Server Response                      │
│  ┌──────────────────────────────────────────────────┐  │
│  │  JSON: { text: "...", isFinal: true/false }     │  │
│  └────────────────────┬─────────────────────────────┘  │
└────────────────────────┼────────────────────────────────┘
                         │
                         │ WebSocket (WSS)
                         │
┌────────────────────────▼────────────────────────────────┐
│                    Client UI Update                     │
│  ┌──────────────────────────────────────────────────┐  │
│  │  1. Display Interim Result (Gray)                │  │
│  │  2. Display Final Result (Black)                 │  │
│  │  3. Update Transcript View                       │  │
│  └──────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
```

### 5.4. 통신 프로토콜

#### Client → Server 메시지

| 이벤트 타입 | 데이터 형식 | 예시 |
|-------------|-------------|------|
| `start_stream` | JSON | `{ "event": "start_stream", "config": { "sampleRate": 16000, "encoding": "pcm_s16le" } }` |
| `audio_data` | JSON (Base64) | `{ "event": "audio_data", "payload": "SGVsbG8gV29ybGQ..." }` |
| `end_stream` | JSON | `{ "event": "end_stream", "reason": "user_stop" }` |

#### Server → Client 메시지

| 이벤트 타입 | 데이터 형식 | 예시 |
|-------------|-------------|------|
| `transcript` | JSON | `{ "type": "transcript", "text": "안녕하세요", "isFinal": false, "confidence": 0.95 }` |
| `error` | JSON | `{ "type": "error", "code": 500, "message": "STT Engine timeout" }` |

---

## 6. 사용자 스토리 (User Stories)

### US1. 음성 녹음 시작
- **As a** 사용자
- **I want to** 녹음 버튼을 눌러 음성 녹음을 시작하고
- **So that** 내 음성이 텍스트로 변환되는 것을 볼 수 있다.

**인수 조건 (Acceptance Criteria)**:
1. 녹음 버튼을 누르면 마이크 권한을 요청한다.
2. 권한이 허용되면 녹음이 시작되고, 녹음 중 아이콘이 표시된다.
3. 오디오 시각화(파형 또는 볼륨 미터)가 실시간으로 업데이트된다.

### US2. 실시간 텍스트 확인
- **As a** 사용자
- **I want to** 내가 말하는 동안 화면에 텍스트가 실시간으로 나타나고
- **So that** 음성이 제대로 인식되고 있는지 확인할 수 있다.

**인수 조건 (Acceptance Criteria)**:
1. 사용자가 말을 시작하면 1초 이내에 중간 결과가 표시된다.
2. 중간 결과는 회색으로 표시되어 확정되지 않았음을 나타낸다.
3. 문장이 완성되면 최종 결과가 검은색으로 표시된다.

### US3. 녹음 종료 및 저장
- **As a** 사용자
- **I want to** 녹음을 멈추고 변환된 텍스트를 저장하거나 공유하고
- **So that** 나중에 다시 볼 수 있거나 다른 앱에서 사용할 수 있다.

**인수 조건 (Acceptance Criteria)**:
1. 녹음 중지 버튼을 누르면 녹음이 즉시 종료된다.
2. 변환된 전체 텍스트가 표시되고, 편집 가능하다.
3. 저장 또는 공유 버튼이 활성화된다.

### US4. 네트워크 오류 처리
- **As a** 사용자
- **I want to** 네트워크가 불안정해도 녹음이 계속되고
- **So that** 연결이 복구되면 자동으로 텍스트 변환이 재개된다.

**인수 조건 (Acceptance Criteria)**:
1. WebSocket 연결이 끊기면 사용자에게 경고 메시지가 표시된다.
2. 자동 재연결을 시도하며, 연결 상태가 UI에 표시된다.
3. 재연결 성공 시 버퍼링된 오디오 데이터를 서버로 전송한다.

### US5. 권한 거부 시 안내
- **As a** 사용자
- **I want to** 마이크 권한을 거부했을 때 명확한 안내를 받고
- **So that** 설정에서 권한을 변경하는 방법을 알 수 있다.

**인수 조건 (Acceptance Criteria)**:
1. 마이크 권한이 거부되면 안내 다이얼로그가 표시된다.
2. 다이얼로그에는 설정 앱으로 이동하는 버튼이 포함된다.
3. 권한 변경 후 앱으로 돌아오면 자동으로 재시도한다.

---

## 7. 성공 지표 (Success Metrics)

### 7.1. 정량적 지표

| 지표 | 목표 | 측정 주기 |
|------|------|-----------|
| **인식 정확도** | 90% 이상 | 주 단위 |
| **평균 응답 시간** | 500ms 이하 | 실시간 모니터링 |
| **앱 크래시율** | 1% 미만 | 일 단위 |
| **일일 활성 사용자(DAU)** | 1,000명 | 일 단위 |
| **사용자 평균 세션 시간** | 5분 이상 | 주 단위 |
| **사용자 리텐션(7일)** | 30% 이상 | 주 단위 |

### 7.2. 정성적 지표

- 사용자 만족도 조사: 4.0/5.0 이상
- 앱스토어 평점: 4.5/5.0 이상
- 주요 사용자 피드백: "빠르다", "정확하다", "사용하기 쉽다"

---

## 8. 개발 일정 및 마일스톤

### Phase 1: MVP (Minimum Viable Product) - 4주

| 주차 | 작업 내용 | 담당 | 상태 |
|------|-----------|------|------|
| **Week 1** | 프로젝트 셋업, 아키텍처 설계, 기술 스택 확정 | 전체 팀 | 계획 중 |
| **Week 2** | 클라이언트: 오디오 녹음 + WebSocket 연결<br>서버: WebSocket Echo 서버 구축 | Frontend, Backend | 계획 중 |
| **Week 3** | STT 엔진 통합 (Google Cloud Speech-to-Text)<br>실시간 텍스트 변환 구현 | Backend | 계획 중 |
| **Week 4** | UI/UX 개선 (오디오 시각화, 중간 결과 표시)<br>오류 처리 및 재연결 로직 | Frontend | 계획 중 |

### Phase 2: 안정화 및 최적화 - 3주

| 주차 | 작업 내용 |
|------|-----------|
| **Week 5** | 성능 최적화 (레이턴시 감소, 메모리 최적화) |
| **Week 6** | QA 테스트, 버그 수정 |
| **Week 7** | 베타 테스트, 사용자 피드백 반영 |

### Phase 3: 출시 준비 - 2주

| 주차 | 작업 내용 |
|------|-----------|
| **Week 8** | 앱스토어/플레이스토어 등록 준비 (스크린샷, 설명 작성) |
| **Week 9** | 소프트 런칭 및 모니터링 |

### Phase 4: 후속 기능 개발 (향후 계획)

- 다국어 지원
- 커스텀 단어장
- 음성 명령
- 클라우드 동기화
- 프리미엄 기능 (무제한 녹음 시간, 고급 편집 기능)

---

## 9. 위험 요소 및 제약 사항

### 9.1. 기술적 위험

| 위험 | 영향도 | 발생 가능성 | 완화 방안 |
|------|--------|-------------|-----------|
| **STT 엔진 응답 속도 저하** | 높음 | 중간 | 다중 STT 엔진 지원, Fallback 메커니즘 구현 |
| **네트워크 불안정** | 높음 | 높음 | 자동 재연결, 로컬 버퍼링, 오프라인 모드 검토 |
| **모바일 권한 거부** | 중간 | 중간 | 명확한 권한 요청 설명, 설정 링크 제공 |
| **배터리 소모 과다** | 중간 | 중간 | 오디오 처리 최적화, VAD 적용 |
| **React Native 라이브러리 호환성 문제** | 중간 | 낮음 | 대체 라이브러리 사전 조사, Native Module 개발 고려 |

### 9.2. 비즈니스 위험

| 위험 | 영향도 | 발생 가능성 | 완화 방안 |
|------|--------|-------------|-----------|
| **STT API 비용 증가** | 높음 | 중간 | 사용량 모니터링, 사용자당 제한 설정, 프리미엄 모델 검토 |
| **경쟁사 대비 차별화 부족** | 중간 | 중간 | 실시간 부분 결과 표시 등 UX 차별화, 빠른 속도 강조 |
| **개인정보보호 이슈** | 높음 | 낮음 | 음성 데이터 비저장 정책, 투명한 개인정보 처리방침 |

### 9.3. 제약 사항

- **예산**: STT API 호출 비용 (월 $XXX 한도)
- **인력**: Frontend 1명, Backend 1명, QA 1명
- **일정**: 9주 내 출시 (2025년 2월 중순 목표)
- **기술**: React Native 생태계 내에서 구현 (네이티브 개발 최소화)
- **라이선스**: 오픈소스 라이브러리는 MIT/Apache 라이선스만 사용

---

## 10. 의존성 및 전제 조건

### 10.1. 외부 의존성

- **STT API**: Google Cloud Speech-to-Text API 계정 및 API 키 필요
- **서버 인프라**: AWS/GCP 등 클라우드 서버 환경 구축 필요
- **도메인 및 SSL 인증서**: WebSocket Secure(WSS) 통신을 위한 HTTPS 도메인 필요

### 10.2. 전제 조건

- React Native 개발 환경 셋업 완료 (Xcode, Android Studio)
- 서버 개발 및 배포 경험 보유
- WebSocket 및 실시간 통신에 대한 이해
- STT 엔진 사용 경험 (선택 사항이나 권장)

---

## 11. 참고 자료 (References)

### 11.1. 기술 문서
- [기술 설계서: Real-time Voice Streaming to STT](./Planning.md)
- React Native 공식 문서: https://reactnative.dev/
- Google Cloud Speech-to-Text API: https://cloud.google.com/speech-to-text
- WebSocket 프로토콜: https://datatracker.ietf.org/doc/html/rfc6455

### 11.2. 경쟁사 분석
- **Google Recorder**: 실시간 STT, 오프라인 지원, 검색 기능
- **Otter.ai**: 회의 전사, 협업 기능, 클라우드 동기화
- **Clova Note**: 네이버 Clova AI, 한국어 특화, 발화자 구분

### 11.3. 디자인 참고
- Material Design: https://material.io/
- Apple Human Interface Guidelines: https://developer.apple.com/design/

---

## 12. 승인 및 변경 이력

### 승인

| 역할 | 이름 | 승인일 | 서명 |
|------|------|--------|------|
| Product Manager | | | |
| Tech Lead | | | |
| Stakeholder | | | |

### 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|-----------|--------|
| 1.0 | 2025-12-13 | 초안 작성 | |

---

## 부록 A: 용어 정의

| 용어 | 정의 |
|------|------|
| **STT (Speech-to-Text)** | 음성을 텍스트로 변환하는 기술 |
| **WebSocket** | 클라이언트와 서버 간 양방향 실시간 통신 프로토콜 |
| **PCM (Pulse Code Modulation)** | 아날로그 신호를 디지털로 변환하는 방식 |
| **Interim Results** | STT 엔진이 반환하는 중간 인식 결과 (확정되지 않은 텍스트) |
| **Final Results** | STT 엔진이 반환하는 최종 확정된 인식 결과 |
| **VAD (Voice Activity Detection)** | 음성 구간을 자동으로 감지하는 기술 |
| **Latency** | 입력(음성)부터 출력(텍스트)까지의 지연 시간 |
| **Chunk** | 스트리밍 데이터를 작은 단위로 나눈 조각 |

---

## 부록 B: 주요 개발 체크리스트

### 클라이언트 (React Native)

- [ ] 마이크 권한 요청 및 처리 (iOS, Android)
- [ ] `react-native-live-audio-stream` 라이브러리 통합
- [ ] WebSocket 연결 및 재연결 로직 구현
- [ ] 오디오 데이터 Base64 인코딩 및 전송
- [ ] 중간 결과 및 최종 결과 UI 구분 표시
- [ ] 오디오 시각화 (파형 또는 볼륨 미터) 구현
- [ ] 오류 처리 및 사용자 피드백
- [ ] 텍스트 편집 및 저장 기능
- [ ] 메모리 및 성능 최적화
- [ ] iOS/Android 빌드 및 테스트

### 서버 (Backend)

- [ ] WebSocket 서버 구축 (FastAPI/Express)
- [ ] STT 엔진 연동 (Google Cloud Speech-to-Text)
- [ ] Base64 디코딩 및 PCM 처리
- [ ] 실시간 스트리밍 파이프라인 구현
- [ ] 중간 결과 및 최종 결과 구분 전송
- [ ] 오류 처리 및 로깅
- [ ] VAD (Voice Activity Detection) 적용 고려
- [ ] 성능 모니터링 및 최적화
- [ ] Docker 컨테이너화
- [ ] 배포 및 스케일링 (AWS/GCP)

### QA 및 테스트

- [ ] 단위 테스트 작성 (클라이언트, 서버)
- [ ] 통합 테스트 (End-to-End)
- [ ] 성능 테스트 (레이턴시, 메모리, 배터리)
- [ ] 다양한 네트워크 환경 테스트 (3G, 4G, Wi-Fi, 불안정한 네트워크)
- [ ] 다양한 디바이스 테스트 (iPhone, Android 저사양/고사양)
- [ ] 접근성 테스트 (VoiceOver, TalkBack)
- [ ] 베타 테스트 및 사용자 피드백 수집

---

**문서 끝**

